{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6bee603d",
   "metadata": {},
   "source": [
    "# Taza de aprendizaje\n",
    "\n",
    "*Las redes neuronales se entrenan mediante descenso de gradiente (o medios similares). Comenzamos en algún punto aleatorio y probamos diferentes soluciones (pesos) que buscan minimizar alguna función de costo, en muchas épocas. Qué tan separadas están estas muestras es la tasa de aprendizaje.*\n",
    "\n",
    "*Efecto de la tasa de aprendizaje. ¡Una tasa de aprendizaje demasiado alta significa que podría sobrepasar la solución óptima! Una tasa de aprendizaje demasiado pequeña tomará demasiado tiempo para encontrar la solución óptima. La tasa de aprendizaje es un ejemplo de hiperparámetro.*\n",
    "\n",
    "*Tamaño del lote. Cuántas muestras de entrenamiento se utilizan en cada época. Algo contrario a la intuición: los tamaños de lote más pequeños pueden salir de los \"mínimos locales\" más fácilmente. El tamaño de lote que es demasiado grande puede terminar atascado en la solución incorrecta. El barajado aleatorio en cada época puede hacer que esto parezca resultados muy inconsistentes de una carrera a otra*\n",
    "\n",
    "*Para recapitular. Los tamaños de lote pequeños tienden a no atascarse en los mínimos locales. Los tamaños de lote grandes pueden converger en la solución incorrecta al azar. Las grandes tasas de aprendizaje pueden sobrepasar la solución correcta. Las tasas de aprendizaje pequeñas aumentan el tiempo de capacitación*\n",
    "\n",
    "*¿Qué es la regularización? Prevención del sobreajuste. Modelos que son buenos para hacer predicciones sobre los datos que aprendieron, pero no sobre nuevos datos que no haya visto antes. Los modelos sobreajustados han aprendido patrones en los datos de entrenamiento que no se generalizan al mundo real. A menudo se considera una alta precisión en el conjunto de datos de entrenamiento, pero una menor precisión en el conjunto de datos de prueba o evaluación. Al entrenar y evaluar el modelo, utilizamos el conjunto de datos de entrenamiento, evaluación y prueba. Las técnicas de regularización están destinadas a evitar el sobreajuste*\n",
    "\n",
    "*¿Demasiadas capas?, ¿Demasiadas neuronas? , se puede \"manejar\" utilizando Dropout y tambien \"Early stopping\"*\n",
    "\n",
    "# Etica del aprendizaje profundo (deep learning)\n",
    "\n",
    "*Tipos de errores. La precisión no cuenta toda la historia. Tipo 1: Falso positivo. Cirugía innecesaria. Golpea los descansos sin ninguna razón. Tipo 2: Falso negativo. Condiciones no tratadas. Te chocas contra el auto frente a ti. Piense en las ramificaciones de los diferentes tipos de errores de su modelo, ajústelo en consecuencia*\n",
    "\n",
    "*Sesgos ocultos. El hecho de que tu modelo no sea humano no significa que sea inherentemente justo. Ejemplo: capacite a un modelo sobre qué tipo de solicitantes de empleo son contratados, úselo para filtrar currículums. Los sesgos pasados hacia el género / edad / rece se reflejarán en su modelo, porque se reflejaron en los datos con los que entrenó el modelo.*\n",
    "\n",
    "*¿Es realmente mejor que un humano? No exageres las capacidades de un algoritmo en tu entusiasmo. Ejemplo: diagnósticos médicos que son casi, pero no del todo, tan buenos como un médico humano. Otro ejemplo: coches autónomos que pueden matar a la gente*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9dc401",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
