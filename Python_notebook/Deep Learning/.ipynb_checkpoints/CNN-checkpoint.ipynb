{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94e68287",
   "metadata": {},
   "source": [
    "# Red neuronal convolucional (CNN)\n",
    "\n",
    "*¿Para qué sirven? Cuando tiene datos que no se alinean perfectamente en columnas. Imagen en la que desea encontrar características. Traducción automática. Clasificación de oraciones. Análisis de sentimientos. No pueden encontrar características que no estén en un lugar específico. Como una señal de alto en una imagen. O palabras dentro de una oración. Son \"invariantes de ubicación de características\"*\n",
    "\n",
    "*¿Cómo funcionan? Inspirado en la biología de la corteza visual. Los campos receptivos locales son grupos de neuronas que solo responden a una parte de lo que ven sus ojos (submuestreo). Se superponen entre sí para cubrir todo el campo visual (circunvoluciones). Se alimentan en capas superiores que identifican imágenes cada vez más complejas. Algunos campos receptivos identifican líneas horizontales, líneas en diferentes ángulos, etc. (filtros). Estos alimentarían una capa que identifica formas. Lo que podría alimentar una capa que identifica el objeto. Para imágenes en color, capas adicionales para rojo, verde y azul*\n",
    "\n",
    "*¿Cómo \"sabemos\" que eso es? El campo receptivo local individual escanea la imagen en busca de bordes y recoge los bordes del signo de búsqueda en la capa. Esos bordes a su vez son recogidos por una convolución de nivel superior que identifica la forma del signo de hallazgo (y las letras también). Esta forma luego se compara con su patrón de cómo se ve una señal de alto, también utilizando la fuerte señal roja proveniente de sus capas rojas. ¡Esa información sigue siendo procesada hacia arriba hasta que tu pie pisa el freno! una CNN funciona de la misma manera*\n",
    "\n",
    "**CNN y Keras**\n",
    "\n",
    "*Los datos de origen deben tener dimensiones adecuadas. es decir, ancho x largo x canales de color.  El tipo de capa Conc2D realiza la convolución real en una imagen 2D. Conv1D y Conv3D también están disponibles, no tienen que ser datos de imagen. Las capas MaxPooling2D se pueden utilizar para reducir una capa 2D tomando el valor máximo en un bloque determinado. Las capas aplanadas convertirán la capa 2D en una capa 1D para pasar a una capa oculta plana de neuronas. Uso típico:*\n",
    "\n",
    "*Conv2D -> MaxPooling2D -> Dropout -> Flatten -> Dense -> Dropout -> Softmax*\n",
    "\n",
    "*Las CNN son difíciles. Muy intensivo en recursos (CPU, GPU y RAM). Muchos hiperparámetros. Tamaños de kernel, muchas capas con diferentes números de unidades, cantidad de pooling... Además de las cosas habituales como el número de capas, la elección del optimizador. ¡Obtener los datos de entrenamiento es a menudo la parte más difícil! (Además de almacenarlo y acceder a él)*\n",
    "\n",
    "\n",
    "*Arquitecturas CNN especializadas. Defina la disposición específica de capas, relleno e hiperparámetros. LeNet-5. Bueno para el reconocimiento de escritura a mano. AlexNet. Clasificación de imágenes, más profunda que LeNet. GoogleLeNet. Aún más profundo, pero con mejor rendimiento. Introduce módulos de inceoción (grupo de capas de convolución). ResNet (red residual). Aún más profundo, mantiene el rendimiento a través de conexiones de omisión*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbd7d938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
