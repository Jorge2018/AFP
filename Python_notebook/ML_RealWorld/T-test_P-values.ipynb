{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18bf8943",
   "metadata": {},
   "source": [
    "# ¿Cómo uso mi modelo en una aplicación?. \n",
    "\n",
    "*¡Su aplicación externa no puede simplemente ejecutar un bloc de notas!. Separa tu entrenamiento de tus predicciones. Entrene el modelo periódicamente sin conexión. Inserte el modelo, o este resultado, a un servicio web. La aplicación llama al servicio web*\n",
    "\n",
    "# Machine Learning Google Cloud\n",
    "\n",
    "*volcar su clasificador entrenado usando sklearn.externals. Desde sklearn.externals \n",
    "**import joblib joblib.dump(clf, 'model.joblib')** .*Sube model.joblib al almacenamiento en la nube de Google, especificando el marco scikit-learn. Cloud ML Engine expone una API de REST a la que puede llamar para realizar predicciones en tiempo real*\n",
    "\n",
    "*Otros enfoques. Implemente su propio servicio web con flask u otro marco. Luego tiene servidores para aprovisionar y mantener. Apuesta por todo con una plataforma*\n",
    "\n",
    "**¿Qué es una prueba A/B?.**\n",
    "\n",
    "*Un experimento controlado, generalmente en el contexto de un sitio web. Usted prueba el rendimiento de algún cambio en su sitio web (la variante) y mide la conversión en relación con su sitio sin cambios (el control)*\n",
    "\n",
    "*¿Qué tipo de cosas puedes probar?. Cambios de diseño, flujo de interfaz de usuario, cambios algorítmicos, cambios de precios,lo que sea*\n",
    "\n",
    "*¿Cómo se mide la conversión? Lo ideal es elegir lo que está tratando de influir. Importes de pedidos, beneficios, clics en anuncios, cantidad de pedidos. Pero atribuir acciones aguas abajo de su cambio puede ser difícil. Especialmente si estás ejecutando más de un experimento*\n",
    "\n",
    "*La varianza es tu enemigo. Error común. Ejecute una prueba durante un pequeño período de tiempo que resulte en algunas compras para analizar. Tomas la cantidad media de orden de A y B, y declaras la victoria o la derrota. Pero, hay tanta variación aleatoria en el orden de estar con, que su resultado se basó en el azar. Luego te engañas a ti mismo pensando que algún cambio en tu sitio web, que en realidad podría ser perjudicial, ha ganado toneladas de dinero.*\n",
    "\n",
    "*A veces también necesita mirar las métricas de conversación con menos variación. Cantidades de pedido vs montos en dólares de pedido, por ejemplo.*\n",
    "\n",
    "*Determinar la significación, Entonces, ¿cómo sabemos si es probable que un resultado sea \"real\" en comparación con la variación aleatoria? Prueba T y valores P*\n",
    "\n",
    "**T-statistic**\n",
    "\n",
    "*Una medida de la diferencia entre los dos conjuntos expresada en unidad de error estándar. El tamaño de la diferencia en relación con la varianza en los datos. Un valor T alto significa que probablemente haya una diferencia real entre los dos conjuntos. Asume la distribución normal del comportamiento. Esta es una buena suposición si está midiendo la conversión de ingresos y as. Ver también: prueba exacta de Fisher (para tasas de clics), prueba E (para transacciones por usuario) y prueba de chi cuadrado (para cantidades de productos comprados)*\n",
    "\n",
    "\n",
    "**P-value**\n",
    "\n",
    "*Piense en ello como la probabilidad de que A y B satisfagan la \"hipotesis nula\". Por lo tanto, un valor p bajo implica significación. Es la probabilidad de que una observación se encuentre en un valor t extremo asumiendo la hipótesis nula.*\n",
    "\n",
    "*Elija algún umbral para \"importancia\" antes de su experimento. 1%, 5%? Cuando termine el experimento: Mide tu valor P.  Si es menor que su umbral de significación, entonces puede rechazar la hipótesis nula. Si es un cambio positivo, despliégalo. Si es un cambio negativo, deséchelo antes de perder más dinero*\n",
    "\n",
    "\n",
    "**¿Cómo sé cuándo he terminado con una prueba A/B?**\n",
    "\n",
    "*Has alcanzado significancia (positiva o negativa). Ya no observas tendencias significativas en tu valor p. Es decir, no ve una indicación de que su experimento \"convergerá\" en un resultado con el tiempo. Alcanzas un límite superior preestablecido en un tiempo.*\n",
    "\n",
    "*La correlación no implica causalidad. ¡Incluso su baja puntuación de valor p en un experimento bien diseñado no implica causalidad! Todavía podría ser casualidad. Otros factores podrían estar en juego. Es su deber asegurarse de que los dueños de negocios entiendan esto.*\n",
    "\n",
    "*Efectos de novedad. Los cambios en un sitio web llamarán la atención de los usuarios anteriores que están acostumbrados a la forma en que solía ser. Hacen clic en algo simplemente porque es nuevo. Pero esta atención no durará para siempre. Buena idea volver a ejecutar experimentos mucho más tarde y validar su impacto. A menudo, el sitio web \"antiguo\" superará al \"nuevo\" después de un tiempo, simplemente porque es un cambio.*\n",
    "\n",
    "*Efectos estacionales. Un experimento ejecutado durante un corto período de tiempo solo puede ser válido para ese período de tiempo. Ejemplo: El comportamiento del consumidor cerca de Navidad es muy diferente al de otras épocas del año. Un experimento realizado cerca de Navidad puede no representar el comportamiento durante el resto del año*\n",
    "\n",
    "*Sesgo BIAS. A veces, su selección aleatoria de clientes para A o B no es realmente aleatoria. Por ejemplo: la asignación se basa de alguna manera en el ID del cliente. Pero los clientes con identificaciones bajas son mejores clientes que los que tienen identificaciones altas. Ejecute una prueba A/A periódicamente para verificar. Audite sus algoritmos de asignación de segmentos*\n",
    "\n",
    "*Contaminación de datos. ¿Los robots (tanto autoidentificados como maliciosos) están afectando su experimento? Una buena razón para medir la conversión en función de algo que requiere gastar dinero real. En términos más generales, ¿los valores atípicos están sesgando el resultado?*\n",
    "\n",
    "*A menudo hay errores en la forma en que se atribuye la conversión a un experimento. El uso de una plataforma de prueba A / B ampliamente utilizada puede ayudar a mitigar ese riesgo. Si eres de cosecha propia, merece una auditoría. Esté atento a las \"áreas grises\". ¿Está contando las compras para un experimento dentro de un marco de tiempo determinado de exposición a él? ¿Es ese tiempo demasiado grande? ¿Podrían otros cambios posteriores al cambio que está midiendo afectar sus resultados? ¿Está ejecutando varios experimentos a la vez?*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65fe6df",
   "metadata": {},
   "source": [
    "# T-test and P-values\n",
    "\n",
    "*Digamos que estamos ejecutando una prueba A / B. Fabricaremos algunos datos que asignan aleatoriamente cantidades de pedidos de clientes en los conjuntos A y B, siendo B un poco más alto:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9277f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-14.639957664974075, pvalue=2.776688447802567e-48)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "A = np.random.normal(25.0, 5.0, 10000)\n",
    "B = np.random.normal(26.0, 5.0, 10000)\n",
    "\n",
    "stats.ttest_ind(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6f8dd86",
   "metadata": {},
   "source": [
    "*El estadístico t es una medida de la diferencia entre los dos conjuntos expresada en unidades de error estándar. Dicho de otra manera, es el tamaño de la diferencia en relación con la varianza en los datos. Un valor t alto significa que probablemente haya una diferencia real entre los dos conjuntos; Tienes \"significado\". El valor p es una medida de la probabilidad de que una observación se encuentre en valores t extremos; Por lo tanto, un valor p bajo también implica \"significación\". Si está buscando un resultado \"estadísticamente significativo\", desea ver un valor p muy bajo y una estadística t alta (bueno, un valor absoluto alto de la estadística t con mayor precisión). \n",
    "En el mundo real, los estadísticos parecen poner más peso en el resultado del valor p.*\n",
    "\n",
    "*Cambiemos las cosas para que tanto A como B sean aleatorios, generados bajo los mismos parámetros. Así que no hay diferencia \"real\" entre los dos:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "959c5950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.5852060075683267, pvalue=0.5584158088214319)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B = np.random.normal(25.0, 5.0, 10000)\n",
    "\n",
    "stats.ttest_ind(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb99126c",
   "metadata": {},
   "source": [
    "*Ahora, nuestra estadística t es mucho más baja y nuestro valor p es realmente alto. Esto apoya la hipótesis nula: que no hay una diferencia real en el comportamiento entre estos dos conjuntos.*\n",
    "\n",
    "*¿El tamaño de la muestra hace alguna diferencia? Hagamos lo mismo, donde la hipótesis nula es precisa, pero con 10 veces más muestras:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0be1bdcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=1.0830314767021316, pvalue=0.2787957575816515)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.normal(25.0, 5.0, 100000)\n",
    "B = np.random.normal(25.0, 5.0, 100000)\n",
    "\n",
    "stats.ttest_ind(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e25a70a",
   "metadata": {},
   "source": [
    "*Nuestro valor p en realidad bajó un poco más, y la prueba t un poco más grande, pero aún no lo suficiente como para declarar una diferencia real. Por lo tanto, podría haber tomado la decisión correcta con solo 10,000 muestras en lugar de 100,000. Incluso un millón de muestras no ayuda, por lo que si siguiéramos ejecutando esta prueba A / B durante años, nunca lograría el resultado que espera:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9dcd64b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=-0.43794431263761147, pvalue=0.6614266993175622)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.random.normal(25.0, 5.0, 1000000)\n",
    "B = np.random.normal(25.0, 5.0, 1000000)\n",
    "\n",
    "stats.ttest_ind(A, B)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "309b228b",
   "metadata": {},
   "source": [
    "*Si comparamos el mismo conjunto consigo mismo, por definición obtenemos un estadístico t de 0 y un valor p de 1:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0ba6752",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ttest_indResult(statistic=0.0, pvalue=1.0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.ttest_ind(A, A)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd01c82f",
   "metadata": {},
   "source": [
    "*El umbral de significación en el valor p es realmente solo una llamada de juicio. Como todo es una cuestión de probabilidades, nunca se puede decir definitivamente que los resultados de un experimento son \"significativos\". Pero puede usar la prueba t y el valor p como una medida de significancia, y observar las tendencias en estas métricas a medida que se ejecuta el experimento para ver si podría haber algo real sucediendo entre los dos.*    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91546297",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
