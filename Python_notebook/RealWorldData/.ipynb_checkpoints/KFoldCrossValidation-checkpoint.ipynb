{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a497724",
   "metadata": {},
   "source": [
    "# Sesgo y varianza. \n",
    "\n",
    "*El sesgo es cuán alejada está la media de sus valores predichos de la respuesta \"real\". La varianza es cuán dispersos están sus valores predichos de la respuesta \"real\". Descriser el sesgo y la varianza de estos cuatro casos (suponiendo que el centro es el resultado correcto)*\n",
    "\n",
    "**A menudo es necesario elegir entre sesgo y varianza. Todo se reduce a sobreajustar vs infrajustar sus datos**\n",
    "*Pero lo que realmente te importa es el error. Tanto el sesgo como la varianza contribuyen al error. Error= (Sesgo*Sesgo) + Varianza. Pero es un error que desea minimizar, no un sesgo o varianza específicamente. Un modelo complejo tendrá varianza y bajo sesgo. Un modelo demasiado simple tendrá baja varianza y alto sesgo. Pero ambos pueden tener el mismo error: la complejidad óptima está en el medio.*\n",
    "*Atándolo a lecciones anteriores. El aumento de K en K-Nearest-Neighboars disminuye la varianza y aumenta el sesgo (al promediar más vecinos). Un solo árbol de decisión es propenso a sobreajustarse: alta varianza. Pero un bosque aleatorio disminuye la varianza*\n",
    "\n",
    "# Validación cruzada K-fold.\n",
    "\n",
    "*Una forma de proteger aún más contra el sobreajuste es la validación cruzada K-fold. Suena complicado: Pero es una idea simple. Divida sus datos en K segmentos asignados aleatoriamente. Reserve un segmento como datos de prueba. Entrene en los segmentos K-1 restantes combinados y mida su rendimiento contra el conjunto de prueba. Repita para cada segmento. Tome el promedio de los puntajes K r cuadrado. Evitar que se sobreajuste a una sola división de tren/prueba*\n",
    "*scikit-learn hace esto realmente fácil. Incluso más fácil que una sola división de triaína / prueba. En la práctica, debe probar diferentes variaciones de su modelo y medir la precisión media utilizando la validación K-fold Cross hasta que encuentre un punto óptimo. Juguemos. Utilice la validación cruzada k-fold con un modelo SVC de clasificación del iris. Veremos que sin K-fold, sobreajustamos el modelo en frío*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b45e58",
   "metadata": {},
   "source": [
    "**Volvamos al conjunto de datos de Iris:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6490a992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import cross_val_score, train_test_split\n",
    "from sklearn import datasets\n",
    "from sklearn import svm\n",
    "\n",
    "iris = datasets.load_iris()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76cc148",
   "metadata": {},
   "source": [
    "*Una sola división de train/test se hace fácil con la función train_test_split en la biblioteca cross_validation:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dc246e55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9666666666666667"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "clf = svm.SVC(kernel='linear', C=1).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf.score(X_test, y_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feccc28a",
   "metadata": {},
   "source": [
    "*La validación cruzada de K-Fold es igual de fácil; usemos una K de 5:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40696a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precision segun pliegue es... [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "La media de la precision, de cada uno de los 5 pliegues es... 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "\n",
    "\n",
    "print('La precision segun pliegue es...',scores)\n",
    "\n",
    "\n",
    "print('La media de la precision, de cada uno de los 5 pliegues es...',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab032677",
   "metadata": {},
   "source": [
    "*¡Nuestro modelo es incluso mejor de lo que pensábamos! ¿Podemos hacerlo mejor? Probemos un kernel diferente (poly):*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed215ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La precision segun pliegue es... [0.96666667 1.         0.96666667 0.96666667 1.        ]\n",
      "La media de la precision, de cada uno de los 5 pliegues es... 0.9800000000000001\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly', C=1).fit(X_train, y_train)\n",
    "\n",
    "scores = cross_val_score(clf, iris.data, iris.target, cv=5)\n",
    "print('La precision segun pliegue es...',scores)\n",
    "\n",
    "\n",
    "print('La media de la precision, de cada uno de los 5 pliegues es...',scores.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d619764",
   "metadata": {},
   "source": [
    "*El núcleo polinómico más complejo produjo menor precisión que un núcleo lineal simple. El núcleo polinómico está sobreajustado. Pero no podríamos haber dicho eso con una sola división de train/test:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0aa313ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = svm.SVC(kernel='poly', C=1).fit(X_train, y_train)\n",
    "\n",
    "clf.score(X_test, y_test)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6792a5c",
   "metadata": {},
   "source": [
    "*Esa es casi la misma puntuación que obtuvimos con una sola división de train/test en el kernel lineal.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83329f21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
